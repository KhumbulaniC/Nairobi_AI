{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout,Flatten, Dense, Activation, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "from matplotlib.image import imread\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '.\\data'\n",
    "os.listdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = f\"{dir_path}\\\\train\\\\\"\n",
    "test_path = f\"{dir_path}\\\\test\\\\\"\n",
    "os.listdir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.choice(os.listdir(train_path + 'with_mask'))\n",
    "parasite_cell = train_path + 'with_mask\\\\'+ sample\n",
    "plt.imshow(plt.imread(parasite_cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height=[]\n",
    "width=[]\n",
    "for image in os.listdir(test_path+'with_mask'):\n",
    "    image = imread(test_path+'\\\\with_mask\\\\'+image)\n",
    "    h, w, colors = image.shape\n",
    "    height.append(h)\n",
    "    width.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (350, 350, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning.\n",
    "- Transfer learning is a machine learning method where we reuse a pre-trained model as the starting point for a model on a new task.\n",
    "- In CNNs we can the feature extraction layers (Convolution Layers) from a model that has already been trained.\n",
    "- This approach enables us to keep the pretrained weights for feature extraction layers, which means we only need to train the prediction layers(Fully connected layer).\n",
    "- There are many established CNN architecture for image classification that you can use as the base model.\n",
    "\n",
    "#### Advantages of Transfer Learning\n",
    "- It saves time and resources. Most machine learning problems involve training a large amount of data. This type of labeled training data takes more time. However, in transfer learning most models are pre-trained, which reduces the size of training data.\n",
    "- It improves the efficiency of a model while training. Developing machine learning models to solve complex problems is time-consuming. With transfer learning, you donâ€™t need to create a model from scratch. You can reuse the developed model by transferring its knowledge.\n",
    "- Instead of using different algorithms to solve new problems, transfer learning provides a more generalized way of solving the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the VGG16 model\n",
    "- Initialize the weights and input size.\n",
    "- **include_top=False** - Means discard the weights for the input and output layers from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights = 'imagenet', include_top=False, input_shape = image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model input\n",
    "base_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't retrain the layers in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the fully connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headmodel = base_model.output\n",
    "headmodel = MaxPooling2D(pool_size=(7,7))(headmodel)\n",
    "headmodel = Flatten(name = 'Flatten')(headmodel)\n",
    "headmodel = Dense(128, activation='relu')(headmodel)\n",
    "headmodel = Dropout(0.5)(headmodel)\n",
    "headmodel = Dense(2,activation='softmax')(headmodel)\n",
    "\n",
    "model = Model(inputs = base_model.input,outputs=headmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks\n",
    "- **Callbacks** are objects in tensorflow & keras that are designed to monitor the model performance in metrics between epochs.\n",
    "- **Early stopping** Stop training when a monitored metric has stopped improving. Assuming the goal of a training is to minimize the loss.\n",
    "- **monitor='val_loss'** to use validation loss as performance measure to terminate the training.</p>\n",
    "    \n",
    "- **patience=0:** is the number of epochs with no improvement. The value 0 means the training is terminated as soon as the performance measure gets worse from one epoch to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "Epochs = 20\n",
    "batch = 16\n",
    "optimizer = Adam(lr = learning_rate)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation\n",
    "- We use the **preprocess_input** because it conatins the same preprocessing as in the model training.\n",
    "- Other parameters are used to generate different variations of the same images. \n",
    "- This increases the overall number of images for training as well as reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range = 20,\n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range= 0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = image_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=image_size[:2],\n",
    "    color_mode= \"rgb\",\n",
    "    batch_size=batch,\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = image_generator.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=image_size[:2],\n",
    "    color_mode= \"rgb\",\n",
    "    batch_size=batch,\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch = len(train_data)/batch,\n",
    "    validation_data=test_data,\n",
    "    validation_steps=len(test_data)/batch,\n",
    "    epochs = Epochs,\n",
    "    callbacks = [early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
